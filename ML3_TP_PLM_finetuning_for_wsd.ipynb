{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.9"
    },
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "4c3ecd847af94205aede82c3c567b0c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1734a3f942c64dae98850b63ef1550d6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_a17a483919304837b1ab63ae47390825",
              "IPY_MODEL_97f7c7b5329240ea99d307b80f93e0e0"
            ]
          }
        },
        "1734a3f942c64dae98850b63ef1550d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a17a483919304837b1ab63ae47390825": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_4e0072f091c54326bb0272ef1f58a981",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1496,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1496,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_29a454e5593648dbaf403886a49468a0"
          }
        },
        "97f7c7b5329240ea99d307b80f93e0e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2fc505931041432fa0cf7d703ffaece2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.50k/1.50k [00:00&lt;00:00, 40.3kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_106b71ece73a476a857bfd8f5ac2c0d9"
          }
        },
        "4e0072f091c54326bb0272ef1f58a981": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "29a454e5593648dbaf403886a49468a0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2fc505931041432fa0cf7d703ffaece2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "106b71ece73a476a857bfd8f5ac2c0d9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e804ae4f4004c25b7766a5c6ed62968": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9a30637cb74545ff907dcdb775fe900f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bb83fde3219e44b688a614f9bd7f7ea7",
              "IPY_MODEL_bcfa7945f2d34b39b8b28685431c9d67"
            ]
          }
        },
        "9a30637cb74545ff907dcdb775fe900f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb83fde3219e44b688a614f9bd7f7ea7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_eb80628ce11c4acdaaf8916036b05bb0",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1561415,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1561415,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_84adfc28855e43f79a39947c67e42661"
          }
        },
        "bcfa7945f2d34b39b8b28685431c9d67": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c70427e1b6143d098df5d21e9d6fb30",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.56M/1.56M [00:01&lt;00:00, 1.07MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_90ef0a52ae0341d49510a21c51c844de"
          }
        },
        "eb80628ce11c4acdaaf8916036b05bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "84adfc28855e43f79a39947c67e42661": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c70427e1b6143d098df5d21e9d6fb30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "90ef0a52ae0341d49510a21c51c844de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "fba94f149c3640b7b92c3e04ea02b72d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b2f3e329a7bc47c68662d9550850e805",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e46894d371f04e508340df8a76e25b69",
              "IPY_MODEL_c6074a05fbe941129222cfbac07d9d9b"
            ]
          }
        },
        "b2f3e329a7bc47c68662d9550850e805": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e46894d371f04e508340df8a76e25b69": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c887452d38854a608ce5e3c4d116a537",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 895731,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 895731,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_49e5aa89ac92441ca6023431e1928f72"
          }
        },
        "c6074a05fbe941129222cfbac07d9d9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b6c227ce31d2421eab3605ae3ce02bca",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 896k/896k [00:00&lt;00:00, 2.02MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11a35fc84b9245d38be3c55d8587f995"
          }
        },
        "c887452d38854a608ce5e3c4d116a537": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "49e5aa89ac92441ca6023431e1928f72": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b6c227ce31d2421eab3605ae3ce02bca": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11a35fc84b9245d38be3c55d8587f995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ADMDWc5LgpC0"
      },
      "source": [
        "\n",
        "---\n",
        "\n",
        "# WSD by fine-tuning a transformer-based pre-trained model\n",
        "\n",
        "**Copy this notebook (File>Save a copy in Drive)**\n",
        "\n",
        "**Add your name in notebook's name**\n",
        "\n",
        "**Deadlines**\n",
        "- send me a shared link by email with subject \"ML3 finetuning for WSD + last NAME + NAME\", before **Dec 27**\n",
        "- don't forget to give me **edit rights**\n",
        "- the execution traces should be visible\n",
        "- **Strong advice**:\n",
        "  - do the TODO1 and TODO2 by next lab session (Dec 8)\n",
        "  - freeze the FlauBERT's parameters in your preliminary experiments AND check you did it right\n",
        "  - don't forget to enable the use of a gpu on colab:\n",
        "  - Runtime > Change runtime type > Hardware accelerator => select \"T4 GPU\", which is enough\n",
        "  - ExÃ©cution > Modifier le type d'exÃ©cution > AccÃ©lÃ©rateur matÃ©riel > T4 GPU\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sUrBv8Gvg2bE"
      },
      "source": [
        "We will use the French FrameNet \"[ASFALDA](http://asfalda.linguist.univ-paris-diderot.fr/frameIndex.xml)\" dataset to experiment the Word Sense Disambiguation task (WSD).\n",
        "\n",
        "In this dataset, some words have been manually associated with a semantic frame:\n",
        "- these words are called the **\"targets\"**\n",
        "- find the correct frame for a given word token corresponds to a word sense disambiguation task **(WSD)**\n",
        "- note though that a single frame pertains to several lexical units (e.g. FR_Commerce_buy => acheter.v, achat.n, acquÃ©rir.v, etc...)\n",
        "- for this lab session, sentences containing several targets have been duplicated: each line corresponds to a (sentence, target) pair.\n",
        "\n",
        "FrameNet data also contains annotations for the semantic roles of semantic arguments (Buyer, Seller, Goods ...), which will be ignored for this lab session.\n",
        "\n",
        "So, the objective of this lab is to build a classifier:\n",
        "- input = a (sentence, target) pair\n",
        "- output = a probability distribution over the various \"senses\" (namely frames)\n",
        "  - in basic version, we do not impose that a given target be only associated with its possible senses (namely those that were seen in the training data for this target lemma).\n",
        "\n",
        "A central trait of our classifier will be to use the contextual representation of the target, as output by a transformer-based pre-trained language model.\n",
        "\n",
        "Note that *BERT*-like models provide vectors for tokens, each token being potentially a subword.\n",
        "**In your base version, you will use the FlauBERT vector of the FIRST token of the target word.**\n",
        "\n",
        "Example: for the target *comprenions* in:\n",
        "\n",
        "*Nous comprenions bien le cours*\n",
        "\n",
        "tokenized as :\n",
        "\n",
        "'\\<s>', 'Nous\\</w>', 'compren', 'ions\\</w>', 'bien\\</w>', 'le\\</w>', 'cours\\</w>', '.\\</w>, '\\</s>'\n",
        "\n",
        "you will use the last hidden vector of \"compren\".\n",
        "\n",
        "The base classifier will be a neural network comprising\n",
        "- the pre-trained language model\n",
        "- which provides the hidden vector of the 1st token of the target word\n",
        "- plus a simple linear layer + softmax into the set of frames seen in the training set.\n",
        "\n",
        "We have a single classifier for all lemmas. In the base version, we put no constraint on which frames can be associated with a given target-lemma.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp3IN9YQexxx"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "#from tqdm import tqdm\n",
        "from tqdm.notebook import tqdm # for progress bars in notebooks\n",
        "from random import shuffle\n",
        "import os\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_c3C5Pzexx-"
      },
      "source": [
        "## Naming conventions\n",
        "\n",
        "- sentences are already segmented into words (with a rule-based tokenizer)\n",
        "- but are not segmented into subwords yet\n",
        "- we use \"word\" or \"w\" for the tokens obtained after pre-segmentation\n",
        "- and \"token\" for units obtained after *BERT*-like tokenization (BPE ou WordPiece etc...)\n",
        "\n",
        "- in variable names, we distinguish\n",
        " - integer identifiers for symbols\n",
        "   (for the token vocabulary, the frame vocabulary ...)\n",
        " - versus the rank of a unit (either word or token) within a sequence\n",
        "- tid => token identifier\n",
        "- wrk => rank of a word in a the pre-tokenized sequence\n",
        "- trk => rank of a token in a bert*-tokenized sequence\n",
        "- tg => \"target\", so\n",
        " - tg_wrk = rank of the target word\n",
        " - tg_trk = rank of the first token of the target\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvqLZ8HGR-GT"
      },
      "source": [
        "## Get a variable for the device (CPU or GPU)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1clXe8e2SBta"
      },
      "source": [
        "# in order to use a GPU\n",
        "# modify notebook settings:\n",
        "# Runtime > Change runtime type > Hardware accelerator => select \"T4 GPU\", which is enough\n",
        "\n",
        "# if a GPU is available, we will use it\n",
        "if torch.cuda.is_available():\n",
        "    # object torch.device\n",
        "    DEVICE = torch.device(\"cuda\")\n",
        "\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    device_id = torch.cuda.current_device()\n",
        "    gpu_properties = torch.cuda.get_device_properties(device_id)\n",
        "    print(\"We will use GPU %d (%s) of compute capability %d.%d with \"\n",
        "          \"%.2fGb total memory.\\n\" %\n",
        "          (device_id,\n",
        "          gpu_properties.name,\n",
        "          gpu_properties.major,\n",
        "          gpu_properties.minor,\n",
        "          gpu_properties.total_memory / 1e9))\n",
        "\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    DEVICE = torch.device(\"cpu\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vfm0CXb9exyF"
      },
      "source": [
        "## \"ASFALDA\" dataset\n",
        "\n",
        "A French FrameNet, comprising about 16000 annotated targets, into about 100 distinct frames, along with their semantic role annotations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kySX0ye3jdpP"
      },
      "source": [
        "### Fetching the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YRkusCSCjg8I",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "outputId": "c1c0708f-5d7e-42d6-ab55-4e81f7ddac91"
      },
      "source": [
        "if not os.path.exists('./asfalda_data_for_wsd/'):\n",
        "  # shell commands can be run using !\n",
        "  !pip install wget\n",
        "  import wget\n",
        "\n",
        "  # The URL for the dataset zip file.\n",
        "  url = 'http://www.linguist.univ-paris-diderot.fr/~mcandito/divers/asfalda_data_for_wsd.tgz'\n",
        "\n",
        "\n",
        "  if not os.path.exists('./asfalda_data_for_wsd.tgz'):\n",
        "    print('Downloading dataset')\n",
        "    wget.download(url, './asfalda_data_for_wsd.tgz')\n",
        "    !tar zxf asfalda_data_for_wsd.tgz"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting wget\n",
            "  Downloading https://files.pythonhosted.org/packages/47/6a/62e288da7bcda82b935ff0c6cfe542970f04e29c756b0e147251b2fb251f/wget-3.2.zip\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-cp36-none-any.whl size=9682 sha256=7ebe89a3ae97d8dce0fb0aa081b5eeec94dd6f1acb1e093c5b17db81643c1bb8\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/15/30/7d8f7cea2902b4db79e3fea550d7d7b85ecb27ef992b618f3f\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n",
            "Downloading dataset\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_2cjFvYfOn3"
      },
      "source": [
        "### Data loading method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fYQhZaBzexyF"
      },
      "source": [
        "def load_asfalda_data(gold_data_file, split_info_file):\n",
        "    \"\"\"\n",
        "        Inputs: - asfalda gold data file\n",
        "                - file indicating the corpus type for each sentence id\n",
        "\n",
        "        Returns 4 dictionaries (whose keys are corpus types (train/dev/test))\n",
        "        - sentences = list of sentences, each sent is a list of words\n",
        "        - list of rank of target word in each sentence\n",
        "        - list of target lemmas\n",
        "        - gold labels\n",
        "\n",
        "        Example:\n",
        "        sentences['train'] = [[ ]]\n",
        "         # the targets are the 3rd and first words\n",
        "        tg_wrks['train'] = [2, 0]\n",
        "        tg_lemmas['train'] = ['comprendre', 'comprendre']\n",
        "        labels['train'] = ['frame1', 'frame2']\n",
        "\n",
        "    \"\"\"\n",
        "    # load the usual split into train / dev / test\n",
        "    s = open(split_info_file)\n",
        "    lines = [ l[:-1].split('\\t') for l in s.readlines() ]\n",
        "    split_info_dic = { line[0]:line[1] for line in lines }\n",
        "\n",
        "    # dev / train / test sentences\n",
        "    sentences = {'dev':[], 'train':[], 'test':[]}\n",
        "    # the word ranks (wrk) for the target words\n",
        "    tg_wrks = {'dev':[], 'train':[], 'test':[]}\n",
        "    # target lemmas\n",
        "    tg_lemmas = {'dev':[], 'train':[], 'test':[]}\n",
        "    # the labels of targets (= frames)\n",
        "    labels = {'dev':[], 'train':[], 'test':[]}\n",
        "\n",
        "    max_sent_len = {'dev':0, 'train':0, 'test':0}\n",
        "    max_tg_wrk = {'dev':0, 'train':0, 'test':0}\n",
        "\n",
        "    stream = open(gold_data_file)\n",
        "    for line in stream.readlines():\n",
        "        if line.startswith('#'):\n",
        "            continue\n",
        "        line = line.strip()\n",
        "        (sentid, tg_wrk, frame_name, tg_lemma, tg_pos, rest) = line.split('\\t',5)\n",
        "        # role annotation is ignored\n",
        "        # sentences are pre-segmented into space-separated words\n",
        "        # => we split on space, and will use the is_split_into_words=True mode of the FlauBERT tokenizer\n",
        "        sentence = rest.split(\"\\t\")[-1].split(' ')\n",
        "        part = split_info_dic[sentid]\n",
        "        tg_wrk = int(tg_wrk)\n",
        "\n",
        "        l = len(sentence)\n",
        "        sentences[part].append(sentence)\n",
        "        labels[part].append(frame_name)\n",
        "        tg_wrks[part].append(tg_wrk)\n",
        "        tg_lemmas[part].append(tg_lemma)\n",
        "        if max_sent_len[part] < l:\n",
        "            max_sent_len[part] = l\n",
        "        if max_tg_wrk[part] < tg_wrk:\n",
        "            max_tg_wrk[part] = tg_wrk\n",
        "    print(\"Max sentence length:\", max_sent_len)\n",
        "    print(\"Max target rank (in words):\", max_tg_wrk)\n",
        "\n",
        "    return sentences, tg_wrks, tg_lemmas, labels\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lo-B32y4c308"
      },
      "source": [
        "### Data loading and defining ids for labels"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaKnFVJ0exyL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "ae783b8a-f989-4223-db1b-50cf32e35e74"
      },
      "source": [
        "gold_data_file = './asfalda_data_for_wsd/sequoiaftb.asfalda_1_3.gold.uniq.nofullant.txt'\n",
        "\n",
        "# usual split train / dev / test for this corpus\n",
        "split_info_file = './asfalda_data_for_wsd/sequoiaftb_split_info'\n",
        "\n",
        "sentences, tg_wrks, tg_lemmas, label_strs = load_asfalda_data(gold_data_file,\n",
        "                                                              split_info_file)\n",
        "\n",
        "for p in sentences.keys():\n",
        "    avgl = sum([len(s) for s in sentences[p]])/len(sentences[p])\n",
        "    print(\"%s : %d sentences, average lentgh=%3.2f\"\n",
        "          %(p, len(sentences[p]), avgl))\n",
        "\n",
        "# creating label ids for frames seen in training set\n",
        "i2label = list(set(label_strs['train']))\n",
        "# id for unknown frame (for dev and test)\n",
        "i2label.append('*UNK*')\n",
        "\n",
        "label2i = {x:i for i,x in enumerate(i2label)}\n",
        "# id of special frame \"Other_sense\"\n",
        "i_OTHER_SENSE = label2i['Other_sense']\n",
        "\n",
        "# sequence of gold labels\n",
        "# for each sub-corpus (key = dev/train/test)\n",
        "labels = {}\n",
        "for p in label_strs.keys():\n",
        "    labels[p] = [label2i[x] if x in label2i else label2i['*UNK*'] for x in label_strs[p]]\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Longueur max des phrases: {'dev': 115, 'train': 271, 'test': 140}\n",
            "Rang max du target (en mots): {'dev': 96, 'train': 267, 'test': 115}\n",
            "SPLIT 18657 items into 16792 and 1865\n",
            "SPLIT 18657 items into 16792 and 1865\n",
            "SPLIT 18657 items into 16792 and 1865\n",
            "SPLIT 18657 items into 16792 and 1865\n",
            "dev : 2688 sentences, average lentgh=38.03\n",
            "train : 16792 sentences, average lentgh=38.99\n",
            "test : 3447 sentences, average lentgh=38.45\n",
            "val : 1865 sentences, average lentgh=38.97\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CivIyd0DczNP"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E2Rgiftb-CQ5"
      },
      "source": [
        "### TODO1 : MFS Baseline (\"most frequent sense\")\n",
        "\n",
        "In WSD, a very strong baseline is to always assign the most frequent sense of a word, independently of its context.\n",
        "\n",
        "Note this is a supervised baseline, since we need a sense-annotated corpus to compute the most frequent sense of each word.\n",
        "\n",
        "- Compute the most frequent sense of each **target-lemma**\n",
        "  (using counts found in **train**)\n",
        "\n",
        "- and compute the MFS baseline, namely the accuracy obtained when choosing the most frequent sense of each target\n",
        "  - MFS in train\n",
        "  - MFS in dev (always using frequencies in train to get the most frequent senses)\n",
        "    - **NB**: in case of unknown target lemma, fall back on the most frequent frame in full training data\n",
        "\n",
        "- Study the items in dev that are unknown in train:\n",
        "  - unknown target lemmas\n",
        "  - unknown frame / target-lemma associations\n",
        "  - unknown frames\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d2f7R9YD9_OH"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE28jS8Jgqrz"
      },
      "source": [
        "## Data encoding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPbOlFK9nLoU"
      },
      "source": [
        "### FlauBERT tokenization\n",
        "\n",
        "We use the FlauBERT model, using the Huggingface \"transformers\" module."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G4DfehySexyR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cf38fbb3-a0f8-4c6d-9671-68a86016ae1b"
      },
      "source": [
        "try:\n",
        "  import transformers\n",
        "except ImportError:\n",
        "  !pip install transformers\n",
        "\n",
        "from transformers import AutoModel, AutoTokenizer, AutoConfig\n",
        "\n",
        "# flaubert's tokenization uses as first step a tokenization into words by moses\n",
        "try:\n",
        "  import sacremoses\n",
        "except ImportError:\n",
        "  !pip install sacremoses\n",
        "  import sacremoses\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3a/83/e74092e7f24a08d751aa59b37a9fc572b2e4af3918cb66f7766c3affb1b4/transformers-3.5.1-py3-none-any.whl (1.3MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.3MB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 30.0MB/s \n",
            "\u001b[?25hCollecting tokenizers==0.9.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/34/b39eb9994bc3c999270b69c9eea40ecc6f0e97991dba28282b9fd32d44ee/tokenizers-0.9.3-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 40.7MB/s \n",
            "\u001b[?25hCollecting sentencepiece==0.1.91\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.1MB 40.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=919c56f575837bc66e17dde4691961f409ebc20f4dacf6af49b8efeda8c1ad2a\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.9.3 transformers-3.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JJiKhfxhexyV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 166,
          "referenced_widgets": [
            "4c3ecd847af94205aede82c3c567b0c6",
            "1734a3f942c64dae98850b63ef1550d6",
            "a17a483919304837b1ab63ae47390825",
            "97f7c7b5329240ea99d307b80f93e0e0",
            "4e0072f091c54326bb0272ef1f58a981",
            "29a454e5593648dbaf403886a49468a0",
            "2fc505931041432fa0cf7d703ffaece2",
            "106b71ece73a476a857bfd8f5ac2c0d9",
            "1e804ae4f4004c25b7766a5c6ed62968",
            "9a30637cb74545ff907dcdb775fe900f",
            "bb83fde3219e44b688a614f9bd7f7ea7",
            "bcfa7945f2d34b39b8b28685431c9d67",
            "eb80628ce11c4acdaaf8916036b05bb0",
            "84adfc28855e43f79a39947c67e42661",
            "1c70427e1b6143d098df5d21e9d6fb30",
            "90ef0a52ae0341d49510a21c51c844de",
            "fba94f149c3640b7b92c3e04ea02b72d",
            "b2f3e329a7bc47c68662d9550850e805",
            "e46894d371f04e508340df8a76e25b69",
            "c6074a05fbe941129222cfbac07d9d9b",
            "c887452d38854a608ce5e3c4d116a537",
            "49e5aa89ac92441ca6023431e1928f72",
            "b6c227ce31d2421eab3605ae3ce02bca",
            "11a35fc84b9245d38be3c55d8587f995"
          ]
        },
        "outputId": "d81e6043-7a71-4cbd-bd7d-6fd61c8132cb"
      },
      "source": [
        "# We choose the FlauBERT model\n",
        "\n",
        "# we load tokenizer and config for now\n",
        "flaubert_tokenizer = AutoTokenizer.from_pretrained(\"flaubert/flaubert_base_cased\")\n",
        "flaubert_config = AutoConfig.from_pretrained(\"flaubert/flaubert_base_cased\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4c3ecd847af94205aede82c3c567b0c6",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1496.0, style=ProgressStyle(descriptionâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e804ae4f4004c25b7766a5c6ed62968",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1561415.0, style=ProgressStyle(descriptâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fba94f149c3640b7b92c3e04ea02b72d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=895731.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rMmtutNBexyQ"
      },
      "source": [
        "### TODO2: Encoding method\n",
        "\n",
        "The objective is to apply FlauBERT's tokenization, **keeping track of the position of the tokens of the targets**.\n",
        "\n",
        "Follow the instructions below to fill in the encode method."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uqvpr6ovexya"
      },
      "source": [
        "\n",
        "class WSDEncoder:\n",
        "    def __init__(self, tokenizer, config):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.config = config # to get indices of special tokens\n",
        "\n",
        "\n",
        "    def encode(self, sentences, tg_wrks, max_length=100, verbose=False, is_split_into_words=True):\n",
        "        # - tokenization into subwords (\"tokens\"):\n",
        "        # - substitution by token ids\n",
        "        # - truncation and padding\n",
        "        # - addition of special tokens\n",
        "        # - track of the rank of the first token of target\n",
        "      \"\"\"\n",
        "      Input:\n",
        "        - sentences : list of sentences\n",
        "           -- if is_split_into_words:\n",
        "              sentences are already split into words\n",
        "              (hence sentences = list of word strings [[w1, w2, w3], [w1, w2]...])\n",
        "           -- otherwise, sentences are to split on spaces to get words\n",
        "\n",
        "        - tg_wrks : list of the ranks of target words\n",
        "          (one rank per sentence, starting at 0 in a sentence)\n",
        "        - max_length : maximum length in number of tokens\n",
        "\n",
        "      Returns:\n",
        "        - tid_seqs : the sentences padded/truncated so that each contains max_length token ids\n",
        "        - first_trk_of_targets : for each sentence,\n",
        "                                 the rank in corresponding tid_seq\n",
        "                                 of the first token of the target word\n",
        "\n",
        "      Example with is_split_into_words=True: a batch with one sent\n",
        "      sentences = [ ['ConsÃ©quemment', ',', 'nous', 'comprendrions', '.'] ]\n",
        "      tg_wrks = [3]\n",
        "\n",
        "      if the sentence is tokenized into\n",
        "        '<s>', 'Con', 'sÃ©qu', 'emment</w>', ',</w>', 'nous</w>', 'compr', 'end', 'rions</w>', '.</w>' ....\n",
        "      the first token rank of the target \"comprendrions\" is 6 ('compr')\n",
        "\n",
        "      \"\"\"\n",
        "      # TODO HERE : encoding method\n",
        "\n",
        "      # Indications:\n",
        "      # 1. apply flaubert tokenization *word per word*, and build\n",
        "      #    tid_seqs first without padding / truncation nor special tokens,\n",
        "      #    and keep track of token rank of first token of target word\n",
        "      # 2. then truncate or pad, and add special symbols\n",
        "      # (write several methods for easier reading)\n",
        "\n",
        "      #  return tid_seqs, first_trk_of_targets"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ySTnpTLexyi"
      },
      "source": [
        "#### Encoding test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fK8CV5Bexyj"
      },
      "source": [
        "encoder = WSDEncoder(flaubert_tokenizer, flaubert_config)\n",
        "\n",
        "# test encoder\n",
        "test_sents = [\"ConsÃ©quemment , nous comprendrions .\",\n",
        "              \"Le code comprend des erreurs .\",\n",
        "            \"J' essaie de comprendre les transformers .\",\n",
        "            \"Il n' a pas bien compris le code !\"]\n",
        "\n",
        "# we split into words (cf. asfalda dataset sentences are already split)\n",
        "test_sents = [ x.split(' ') for x in test_sents ]\n",
        "# target words are the occurrences of \"comprendre\"\n",
        "test_tg_wrks = [3, 2, 3, 5]\n",
        "max_length=10\n",
        "\n",
        "# TODO: uncomment to test your encode method\n",
        "#tid_seqs, first_trk_of_targets = encoder.encode(test_sents, test_tg_wrks, max_length=10, verbose=True, is_split_into_words=True)\n",
        "\n",
        "#for tid_seq, ft in zip(tid_seqs, first_trk_of_targets):\n",
        "#    readable = flaubert_tokenizer.convert_ids_to_tokens(tid_seq)\n",
        "#    print(\"Len = %d target token rank = %d tid_seq = %s (%s)\" % (len(tid_seq), ft, str(tid_seq), str(readable)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YHApJ8mgexyn"
      },
      "source": [
        "### TODO3: WSDData class: full encoding and batch production"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMxpzaBhexyo"
      },
      "source": [
        "\n",
        "class WSDData:\n",
        "    def __init__(self, corpus_type, sentences, tg_wrks, tg_lemmas, labels, encoder, max_length=100):\n",
        "        \"\"\"\n",
        "        Inputs:\n",
        "        - corpus type string (train/dev/test)\n",
        "        - list of sentences (each sentence = list of word strings)\n",
        "        - list of target word ranks : one per sentence\n",
        "        - list of gold label id\n",
        "        - encoder = instance of WSDEncoder\n",
        "\n",
        "        - max_length = size of encoded sequences, in nb of bert tokens\n",
        "                      (padded / truncated via encoder.encode)\n",
        "\n",
        "        Encodes all the data using the relevant identifiers\n",
        "        \"\"\"\n",
        "\n",
        "        self.corpus_type = corpus_type # train / dev / test / val\n",
        "        self.size = len(sentences)\n",
        "        self.encoder = encoder\n",
        "\n",
        "        self.labels = labels       # gold label ids\n",
        "        self.sentences = sentences # list of list of word strings\n",
        "        self.tg_lemmas = tg_lemmas\n",
        "\n",
        "        tid_seqs, tg_trks = encoder.encode(sentences, tg_wrks, max_length)\n",
        "\n",
        "        self.tid_seqs = tid_seqs  # sequences of token ids\n",
        "        self.tg_trks = tg_trks    # target token ranks\n",
        "\n",
        "\n",
        "    def shuffle(self):\n",
        "      \"\"\"\n",
        "      Rearranges all the data in a new random order\n",
        "      (sentences, tg_lemmas, tg_trks, tid_seqs, labels)\n",
        "\n",
        "      NB: ** original order might be lost **\n",
        "      \"\"\"\n",
        "      # TODO\n",
        "\n",
        "    # production of a batch\n",
        "    def make_batches(self, batch_size, device, shuffle_data=False):\n",
        "        \"\"\"\n",
        "        Returns an iterator over 3 torch tensors\n",
        "        - batch of token id sequences\n",
        "        - corresponding batch of target token ranks\n",
        "        - corresponding batch of labels for these targets\n",
        "        \"\"\"\n",
        "        # TODO\n",
        "        # (Tip: use \"yield\" function to return an iterator)\n",
        "\n",
        "        # **NB** : the torch tensors can be directly sent to the right device\n",
        "        #          using .to(device)\n",
        "        # for ...\n",
        "        #    ...\n",
        "        #    yield(b_tid_seqs, b_tg_trks, b_labels)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoding of the three sets train/dev/test\n",
        "MAX_LENGTH = 100\n",
        "wsd_data = {}\n",
        "# key = part of the split corpus (train/test/dev)\n",
        "for p in sentences.keys():\n",
        "    print(\"Encoding part %s ...\" % p)\n",
        "    wsd_data[p] = WSDData(p, sentences[p], tg_wrks[p], tg_lemmas[p], labels[p],\n",
        "                          encoder, max_length=MAX_LENGTH)\n",
        "    # we check that encoding provides the right lengths\n",
        "    for i, s in enumerate(wsd_data[p].tid_seqs):\n",
        "        if len(s) != MAX_LENGTH:\n",
        "            print(\"Size bug:\", i, s)\n"
      ],
      "metadata": {
        "id": "fiBeOrXqU718"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIw1BE1wexys"
      },
      "source": [
        "## WSDClassifier class: the network for WSD\n",
        "\n",
        "Base architecture =\n",
        "- the FlauBERT model\n",
        "- plus linear layer + softmax"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i3_mEfGUe3yH"
      },
      "source": [
        "### TODO4: Digression: matrix operation\n",
        "\n",
        "Matrix operation to fetch the bert hidden vector of the first\n",
        "token of the targets.\n",
        "\n",
        "Input is\n",
        "1. x = a tensor for a batch of (truncated/padded) sentences\n",
        "   containing the bert vectors for all tokens of each sentence\n",
        "\n",
        "2. r = a tensor for the token ranks of the first token of the targets\n",
        "  \n",
        "=> we want to keep only the bert vectors of these first tokens\n",
        "\n",
        "TODO: write down the shapes of tensors x and r and of the output tensor\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D0DWembWfXtA"
      },
      "source": [
        "x = torch.tensor([[[1, 2, 3, 4],\n",
        "                   [5, 6, 7, 8],\n",
        "                   [9, 10, 11, 12]],\n",
        "                  [[13, 14, 15, 16],\n",
        "                   [17, 18, 19, 20],\n",
        "                   [21, 22, 23, 24]]])\n",
        "print(x.shape)\n",
        "# if token ranks for the two sentences of the batch are (1,2)\n",
        "r = torch.tensor([1, 2])\n",
        "# => we want to get the [5, 6, 7, 8] and [21, 22, 23, 24] vectors\n",
        "\n",
        "# write down the matrix operation\n",
        "# see this source : https://discuss.pytorch.org/t/how-to-select-specific-vector-in-3d-tensor-beautifully/37724\n",
        "# o = ...\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DQ-w08okgaXv"
      },
      "source": [
        "### TODO5: The network : architecture, forward propagation, evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t-Vpgmjmkn88"
      },
      "source": [
        "flaubert_model = AutoModel.from_pretrained(\"flaubert/flaubert_base_cased\", return_dict=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFQEpfkRexyy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "outputId": "9fe4eb46-841d-41fe-ef37-7075123b4858"
      },
      "source": [
        "class WSDClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, num_labels, device, bert_model, bert_config, freeze_bert = True):\n",
        "        super(WSDClassifier, self).__init__()\n",
        "\n",
        "        self.device = device\n",
        "\n",
        "        # the full *BERT*-like model\n",
        "        # the .to(device) triggers the copy towards the relevant device\n",
        "        # (possibly a GPU)\n",
        "        self.bert_layer = bert_model.to(device)\n",
        "        # config will allow to get the hidden vectors' size\n",
        "        self.bert_config = bert_config\n",
        "\n",
        "        # TODO HERE : rest of the network\n",
        "\n",
        "        # TODO: implement option to either freeze or fine-tune the BERT model\n",
        "\n",
        "\n",
        "    def forward(self, b_tid_seq, b_tg_trk):\n",
        "        \"\"\"\n",
        "        Inputs: (all are tensors, on the relevant device)\n",
        "            - a batch of sentences = a batch of token id sequences\n",
        "              (as output in 'input_ids' member of tokenizer output)\n",
        "            - a batch of target token rank = for each of the sentences,\n",
        "              the rank of first token of the target word to disambiguate\n",
        "\n",
        "        Output: log_softmax scores for the whole batch (batch_size x num_labels)\n",
        "        \"\"\"\n",
        "        # TODO HERE\n",
        "        #  - get the *bert last hidden vectors for all the tokens of all the batch sentences\n",
        "        #    [ batch_size * seq_len * bert_emb_size ]\n",
        "        #\n",
        "        #  - isolate the vector of the (first) token of the target for all the batch sentences\n",
        "        #    [ batch_size * bert_emb_size ]\n",
        "        #\n",
        "        #    Tips to do this:\n",
        "        #    https://discuss.pytorch.org/t/how-to-select-specific-vector-in-3d-tensor-beautifully/37724\n",
        "        #\n",
        "        #  - and apply linear layer\n",
        "\n",
        "    def run_on_dataset(self, wsd_data, batch_size=32):\n",
        "        \"\"\"\n",
        "        Run classifier on wsd_data and compute accuracy\n",
        "        Inputs =\n",
        "         - wsd_data (WSDDataset instance)\n",
        "         - batch_size\n",
        "        Returns:\n",
        "         - list of predicted label ids\n",
        "        \"\"\"\n",
        "        pred_labels = []\n",
        "\n",
        "        # VERY IMPORTANT : toggle evaluation mode of the model (no dropout)\n",
        "        self.eval()\n",
        "\n",
        "        # TODO\n",
        "\n",
        "        return pred_labels\n",
        "\n",
        "    def evaluate(self, gold_labels, pred_labels):\n",
        "        \"\"\" returns accuracy, nb_correct, nb_total \"\"\"\n",
        "        # TODO\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-5bbe513c3a8f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mWSDClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbert_model_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"flaubert/flaubert_base_cased\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreeze_bert\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWSDClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrkbQ4hVexy1"
      },
      "source": [
        "# an instance of WSDClassifier\n",
        "num_labels = len(i2label)\n",
        "classifier = WSDClassifier(num_labels, DEVICE, flaubert_model, flaubert_config)\n",
        "\n",
        "# uncomment to see the huge nb of parameters ...\n",
        "#for name, param in classifier.named_parameters():\n",
        "#    print(\"PARAM named %s, of shape %s\" % (name, str(param.shape)))\n",
        "#    print(param)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6LeXSxEXexy5"
      },
      "source": [
        "#### Test of forward propagation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4iIZvzDexy7"
      },
      "source": [
        "# useless to compute gradients when testing\n",
        "with torch.no_grad():\n",
        "    # toggle train mode off\n",
        "    classifier.eval()\n",
        "    for b_tid_seqs, b_tg_trks, b_labels in data['dev'].make_batches(32, shuffle_data=True):\n",
        "        b_tid_seqs = torch.tensor(b_tid_seqs, device=classifier.device)\n",
        "        b_tg_trks = torch.tensor(b_tg_trks, device=classifier.device)\n",
        "\n",
        "        log_probs = classifier(b_tid_seqs, b_tg_trks)\n",
        "        gold = b_labels[0] #.item()\n",
        "        print(\"GOLD LABEL of first ex %d ( = %s)\" % (gold, i2label[gold]))\n",
        "        print(\"LOG_PROBS before training: %s\\n\\n\" % str(log_probs[0]))\n",
        "        break\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aikfNi0zexy9"
      },
      "source": [
        "### TODO6: Training : fine-tuning for the WSD task\n",
        "\n",
        "**NB** full training on train data is **LONG**, so when developping your code, first try on a small part of the data.\n",
        "\n",
        "**NB** In general when using a *bert model in fine-tuning mode (not frozen), the needed learning rate tends to be lower"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOKrCRPFexy-"
      },
      "source": [
        "# training\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "LR = 0.0005\n",
        "\n",
        "loss_function = nn.NLLLoss(reduction='mean')\n",
        "# SGD is quicker (more convenient for debug phase)\n",
        "#optimizer = optim.SGD(classifier.parameters(), lr=LR)\n",
        "optimizer = optim.Adam(classifier.parameters(), lr=LR)\n",
        "\n",
        "config_name = 'sequoiaftb.asfalda_1_3.wsd.lr' + 'Adam' + str(LR) + '_bs' + str(BATCH_SIZE)\n",
        "out_model_file = './' + config_name + '.model'\n",
        "out_log_file = './' + config_name + '.log'\n",
        "\n",
        "\n",
        "# losses at each epoch (on train / on validation set)\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "min_val_loss = None\n",
        "\n",
        "# to speed up during debug: train on dev\n",
        "#train_data = wsd_data['dev'] # data['train']\n",
        "train_data = wsd_data['train']\n",
        "val_data = wsd_data['dev']\n",
        "\n",
        "# TODO HERE\n",
        "# training\n",
        "# - basic : train for NB_EPOCHS\n",
        "# - BONUS : early stopping: stop epoch loop as soon as accuracy on dev decreases\n",
        "\n",
        "# don't forget to toggle\n",
        "# - classifier.train() when training on train (it will use dropout)\n",
        "# - classifier.eval() when evaluating on val corpus\n",
        "\n",
        "# to speed up: don't compute the gradients when evaluating on dev / test\n",
        "\n",
        "\n",
        "print(\"train losses: %s\" % ' / '.join([ \"%.4f\" % x for x in train_losses]))\n",
        "print(\"val   losses: %s\" % ' / '.join([ \"%.4f\" % x for x in val_losses]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jHt6rTougG0K"
      },
      "source": [
        "### TODO7: Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hHYxcJBNexzB"
      },
      "source": [
        "# TODO HERE : run on dev and evaluate\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Scale (\"barÃ¨me\")\n",
        "\n",
        "- basic system will give 12 points\n",
        "\n",
        "- quality of code / comments = 2 points\n",
        "\n",
        "\n",
        "- various additional points (to choose)\n",
        "\n",
        "  - generalization analysis\n",
        "   Do you think it would be better to predict seen-in-train lemma/frame associations only ?\n",
        "   (in order to answer that question, propose and implement simple analysis of the predictions performed without any control of the frame/lemma association)\n",
        "\n",
        "  - implement an option to only predict seen-in-train lemma/frame associations\n",
        "\n",
        "  - nice hyperparameter search\n",
        "\n",
        "  - high results thanks to nice hyperparameter search\n",
        "\n",
        "  - implement early stopping\n",
        "\n",
        "  - does it help to fine-tune with a MLP instead of single layer ?\n",
        "\n",
        "  - does it help to use a concatenation of flaubert's embeddings at different layers instead of the last layer only (eg 4 last layers, cf. table 7 of devlin et al. 2019) (do this in frozen mode only)\n",
        "\n",
        "  - does it help to add a lemma embedding of the target (concatenate it to the bert output, before final linear layer)?\n",
        "\n",
        "  - ... other ideas are welcome ...\n",
        "\n",
        "Approximate expected accuracy:\n",
        " - In frozen mode, basic system can reach 83 / 84 % on the dev set when well trained\n",
        "\n",
        " - In fine-tuning mode: results seem unstable\n",
        "  - take care to search for an appropriate learning rate, which tends to be lower than in frozen mode\n",
        "  - some of the runs get stuck at 37% of accuracy, corresponding to assigning the MFS to all the instances (\"other_sense\" frame)\n",
        "  - when learning goes well, accuracy can reach 88, or even 90% for some runs\n",
        "\n",
        "\n",
        "NB: write below what you chose to investigate / implement.\n",
        "Summarize your results / hyper-parameter search.\n",
        "For an extra feature to count, you need to write down an analysis of the results.\n",
        "\n",
        "Your notebook should show traces of a complete training and evaluation phase."
      ],
      "metadata": {
        "id": "Y6CDdnT5qXHQ"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmIAkHHqSbXZ"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}